{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1tF-xFkzAhNZLTS2MotrRPI-gJBfRhG2I","timestamp":1652147443927}],"authorship_tag":"ABX9TyPbzKFdcpxfSc+BxZY7+sqf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","\n","iris_dataset = load_iris()\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","\tiris_dataset['data'], iris_dataset['target'], test_size=0.2, random_state=22\n","    )"],"metadata":{"id":"KIF8Zuo_zTWk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","\n","# pipeline 정의\n","pipe_lr = Pipeline(steps=[('standardscaler',StandardScaler()),\n","                          ('logisticregression', LogisticRegression(random_state=22))])\n","\n","print(pipe_lr)"],"metadata":{"id":"unb73pK_055-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe_lr.fit(X_train, y_train)\n","\n","# Accuracy score\n","print(f'Training accuracy: {pipe_lr.score(X_train, y_train)}')\n","print(f'Test accuracy: {pipe_lr.score(X_test, y_test)}')"],"metadata":{"id":"39bakL2WHySu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Plot learning curve\n","from sklearn.model_selection import learning_curve\n","\n","train_sizes, train_scores, test_scores =\\\n","             learning_curve(estimator=?????, X=?????, y=?????,\n","                            train_sizes=np.linspace(0.1, 1.0, 10), cv=10)\n","train_mean = np.mean(train_scores, axis=1)\n","test_mean = np.mean(test_scores, axis=1)\n","\n","plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5,\n","         label='training accuracy')\n","\n","plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s',\n","         markersize=5, label='validation accuracy')\n","\n","plt.grid()\n","plt.xlabel('Number of training samples')\n","plt.ylabel('Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylim([0.8, 1.03])\n","plt.show()"],"metadata":{"id":"B-J03_Y2BSDe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### K-fold cross-validation using pipeline ###\n","from sklearn.model_selection import cross_val_score\n","scores = cross_val_score(estimator=?????, X=?????, y=?????, cv=10)  # Accuracy scores\n","print('CV accuracy scores: %s' % scores)\n","print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"],"metadata":{"id":"05fmwtVTHmSp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Grid search에 의한 초모수 결정 ###\n","from sklearn.model_selection import GridSearchCV\n","param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n","param_grid = [{'?????': param_range}]\n","gs = GridSearchCV(estimator=?????, param_grid=?????, scoring='accuracy', cv=10)\n","gs = gs.fit(?????, ?????)\n","print(gs.best_score_)\n","print(gs.best_params_)"],"metadata":{"id":"RR1N7rviB5sg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bestlr = gs.best_estimator_\n","bestlr.fit(X_train, y_train)\n","print(bestlr.score(X_train,y_train))\n","bestlr.score(X_test, y_test)"],"metadata":{"id":"AY099IW6ccNl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.pipeline import make_pipeline\n","from sklearn.model_selection import cross_validate\n","param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n","total_error = np.zeros(len(param_range))\n","val_error = np.zeros(len(param_range))\n","pipe_lr = make_pipeline(StandardScaler(), LogisticRegression(random_state=22))\n","for idx in range(len(param_range)):\n","  pipe_lr.set_params(logisticregression__C=param_range[idx])\n","  result = cross_validate(estimator=pipe_lr, X=X_train, y=y_train, cv=10,\n","                          return_train_score=True)\n","  total_error[idx] = np.mean(result['train_score'])\n","  val_error[idx] = np.mean(result['test_score'])\n","\n","plt.semilogx(param_range, total_error, color='blue', label='training accuracy')\n","plt.semilogx(param_range, val_error, color='red', label='validation accuracy')\n","\n","plt.grid()\n","plt.xlabel('C')\n","plt.ylabel('Accuracy')\n","plt.legend(loc='lower right')\n","plt.show()"],"metadata":{"id":"L1oR8ZH4DFfT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.svm import SVC\n","from sklearn.model_selection import KFold\n","\n","X_iris = iris_dataset['data']\n","y_iris = iris_dataset['target']\n","\n","# Number of random trials\n","NUM_TRIALS = 30\n","\n","# Set up possible values of parameters to optimize over\n","p_grid = {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}\n","\n","# We will use a Support Vector Classifier with \"rbf\" kernel\n","svm = SVC(kernel=\"rbf\")\n","\n","# Arrays to store scores\n","non_nested_scores = np.zeros(NUM_TRIALS)\n","nested_scores = np.zeros(NUM_TRIALS)\n","\n","# Loop for each trial\n","for i in range(NUM_TRIALS):\n","\n","    # Choose cross-validation techniques for the inner and outer loops,\n","    # independently of the dataset.\n","    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n","    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n","    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n","\n","    # Non_nested parameter search and scoring\n","    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=outer_cv)\n","    clf.fit(X_iris, y_iris)\n","    non_nested_scores[i] = clf.best_score_\n","\n","    # Nested CV with parameter optimization\n","    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv)\n","    nested_score = cross_val_score(clf, X=X_iris, y=y_iris, cv=outer_cv)\n","    nested_scores[i] = nested_score.mean()\n","\n","print(f'Nested CV accuracy: {nested_scores.mean()}')\n","print(f'Non-Nested CV accuracy: {non_nested_scores.mean()}')"],"metadata":{"id":"T0p8ZCgSiAF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot scores on each trial for nested and non-nested CV\n","plt.figure()\n","(non_nested_scores_line,) = plt.plot(non_nested_scores, color=\"r\")\n","(nested_line,) = plt.plot(nested_scores, color=\"b\")\n","plt.ylabel(\"score\", fontsize=\"14\")\n","plt.legend(\n","    [non_nested_scores_line, nested_line],\n","    [\"Non-Nested CV\", \"Nested CV\"],\n","    bbox_to_anchor=(0, 0.4, 0.5, 0),\n",")\n","plt.title(\n","    \"Non-Nested and Nested Cross Validation on Iris Dataset\",\n","    x=0.5,\n","    y=1.1,\n","    fontsize=\"15\",\n",")\n","\n","plt.show()"],"metadata":{"id":"-zzs9jOfit3w"},"execution_count":null,"outputs":[]}]}